{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_utils import data_dict, data_dict_icml, max_episodes_dict, MOUNTAINCARCONTINUOUS_K, PENDULUM_K\n",
    "from run_icml import split_max_episodes\n",
    "from numpy import mean\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeds\n",
    "seeds = [224, 389, 405, 432, 521, 580, 639, 673, 803, 869]\n",
    "seeds_icml = [237, 379, 482, 672, 886]\n",
    "# envs\n",
    "envs = [\"Acrobot-v1\", \"CartPole-v1\", \"MountainCar-v0\", \"MountainCarContinuous-v0\", \"Pendulum-v1\", \"LunarLander-v2\"]\n",
    "# methods\n",
    "methods = [\"binQ\", \"CAT-RL\", \"TileCoding\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of experimnet fixed episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import std\n",
    "\n",
    "\n",
    "data = data_dict(methods, envs, seeds)\n",
    "\n",
    "l = []\n",
    "for env in envs:\n",
    "    for method in methods:\n",
    "        success_rate = []\n",
    "        accumulated_reward = []\n",
    "        avg_reward_ep = []\n",
    "        for seed in seeds:\n",
    "            success_rate.append(mean(data[method][env][seed][\"success\"]))\n",
    "            accumulated_reward.append(sum(data[method][env][seed][\"accumulated reward\"]))\n",
    "            avg_reward_ep.append(mean(data[method][env][seed][\"reward\"]))\n",
    "\n",
    "        \n",
    "        avg_success_rate = mean(success_rate)\n",
    "        std_success_rate = std(success_rate)\n",
    "        avg_accumulated_reward = mean(accumulated_reward)\n",
    "        std_accumulated_reward = std(accumulated_reward)\n",
    "        mean_avg_reward_ep = mean(avg_reward_ep)\n",
    "        std_avg_reward_ep = std(avg_reward_ep)\n",
    "\n",
    "        l.append({\"method\": method,\n",
    "                  \"env\": env,\n",
    "                  \"success rate\": avg_success_rate,\n",
    "                  \"success rate sts\": std_success_rate,\n",
    "                  \"accumulated reward\": avg_accumulated_reward,\n",
    "                  \"accumulated reward std\": std_accumulated_reward,\n",
    "                  \"avg reward per episode\": mean_avg_reward_ep,\n",
    "                  \"avg reward per episode std\": std_avg_reward_ep})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import std\n",
    "\n",
    "algos = [\"ppo\"]\n",
    "data = data_dict_icml(algos, envs, seeds_icml)\n",
    "\n",
    "for env in envs:\n",
    "    for algo in algos:\n",
    "        success_rate = []\n",
    "        accumulated_reward = []\n",
    "        avg_reward_ep = []\n",
    "        for seed in seeds_icml:\n",
    "            success_rate.append(mean(data[algo][env][seed][\"success\"]))\n",
    "            accumulated_reward.append(sum(data[algo][env][seed][\"accumulated reward\"]))\n",
    "            avg_reward_ep.append(mean(data[algo][env][seed][\"rewards\"]))\n",
    "        \n",
    "        avg_success_rate = mean(success_rate)\n",
    "        std_success_rate = std(success_rate)\n",
    "        avg_accumulated_reward = mean(accumulated_reward)\n",
    "        std_accumulated_reward = std(accumulated_reward)\n",
    "        mean_avg_reward_ep = mean(avg_reward_ep)\n",
    "        std_avg_reward_ep = std(avg_reward_ep)\n",
    "\n",
    "        l.append({\"method\": algo,\n",
    "                  \"env\": env,\n",
    "                  \"success rate\": avg_success_rate,\n",
    "                  \"success rate sts\": std_success_rate,\n",
    "                  \"accumulated reward\": avg_accumulated_reward,\n",
    "                  \"accumulated reward std\": std_accumulated_reward,\n",
    "                  \"avg reward per episode\": mean_avg_reward_ep,\n",
    "                  \"avg reward per episode std\": std_avg_reward_ep})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>env</th>\n",
       "      <th>success rate</th>\n",
       "      <th>success rate sts</th>\n",
       "      <th>accumulated reward</th>\n",
       "      <th>accumulated reward std</th>\n",
       "      <th>avg reward per episode</th>\n",
       "      <th>avg reward per episode std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAT-RL</td>\n",
       "      <td>Acrobot-v1</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-347618363.500</td>\n",
       "      <td>79685500.774</td>\n",
       "      <td>-55.285</td>\n",
       "      <td>53.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAT-RL</td>\n",
       "      <td>CartPole-v1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>251650810.200</td>\n",
       "      <td>57390804.337</td>\n",
       "      <td>13.599</td>\n",
       "      <td>3.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CAT-RL</td>\n",
       "      <td>LunarLander-v2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-4025443733.564</td>\n",
       "      <td>71502043.625</td>\n",
       "      <td>-196.053</td>\n",
       "      <td>6.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAT-RL</td>\n",
       "      <td>MountainCar-v0</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.020</td>\n",
       "      <td>14464492011.118</td>\n",
       "      <td>580858094.467</td>\n",
       "      <td>1161.639</td>\n",
       "      <td>48.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CAT-RL</td>\n",
       "      <td>MountainCarContinuous-v0</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.423</td>\n",
       "      <td>188131599.149</td>\n",
       "      <td>42681942.763</td>\n",
       "      <td>369.512</td>\n",
       "      <td>89.419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAT-RL</td>\n",
       "      <td>Pendulum-v1</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-19360056614.880</td>\n",
       "      <td>1090619204.989</td>\n",
       "      <td>-924.669</td>\n",
       "      <td>139.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TileCoding</td>\n",
       "      <td>Acrobot-v1</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.021</td>\n",
       "      <td>1020687281.900</td>\n",
       "      <td>92993773.390</td>\n",
       "      <td>628.536</td>\n",
       "      <td>25.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TileCoding</td>\n",
       "      <td>CartPole-v1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>185847254.600</td>\n",
       "      <td>1584575.768</td>\n",
       "      <td>10.062</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TileCoding</td>\n",
       "      <td>LunarLander-v2</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-1761775790.133</td>\n",
       "      <td>37050527.710</td>\n",
       "      <td>-97.726</td>\n",
       "      <td>2.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TileCoding</td>\n",
       "      <td>MountainCar-v0</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1355634141.843</td>\n",
       "      <td>154421772.818</td>\n",
       "      <td>107.614</td>\n",
       "      <td>8.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TileCoding</td>\n",
       "      <td>MountainCarContinuous-v0</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.036</td>\n",
       "      <td>534508976.190</td>\n",
       "      <td>41252351.573</td>\n",
       "      <td>1045.615</td>\n",
       "      <td>113.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TileCoding</td>\n",
       "      <td>Pendulum-v1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-12713250241.144</td>\n",
       "      <td>193108847.194</td>\n",
       "      <td>-672.821</td>\n",
       "      <td>10.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>binQ</td>\n",
       "      <td>Acrobot-v1</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-133942787.800</td>\n",
       "      <td>51462217.431</td>\n",
       "      <td>129.762</td>\n",
       "      <td>22.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>binQ</td>\n",
       "      <td>CartPole-v1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>205773254.000</td>\n",
       "      <td>5570689.014</td>\n",
       "      <td>10.484</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>binQ</td>\n",
       "      <td>LunarLander-v2</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-1833856965.663</td>\n",
       "      <td>28385863.582</td>\n",
       "      <td>-94.906</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>binQ</td>\n",
       "      <td>MountainCar-v0</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.013</td>\n",
       "      <td>777513395.587</td>\n",
       "      <td>97302647.137</td>\n",
       "      <td>173.669</td>\n",
       "      <td>16.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>binQ</td>\n",
       "      <td>MountainCarContinuous-v0</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.023</td>\n",
       "      <td>661400922.269</td>\n",
       "      <td>23920781.425</td>\n",
       "      <td>1192.967</td>\n",
       "      <td>49.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>binQ</td>\n",
       "      <td>Pendulum-v1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-15616340075.446</td>\n",
       "      <td>131421759.473</td>\n",
       "      <td>-668.949</td>\n",
       "      <td>10.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ppo</td>\n",
       "      <td>Acrobot-v1</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-154483956.000</td>\n",
       "      <td>314872.537</td>\n",
       "      <td>-483.553</td>\n",
       "      <td>2.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ppo</td>\n",
       "      <td>CartPole-v1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>61333226.200</td>\n",
       "      <td>652239.629</td>\n",
       "      <td>21.256</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ppo</td>\n",
       "      <td>LunarLander-v2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-236985767.351</td>\n",
       "      <td>10486693.915</td>\n",
       "      <td>-82.696</td>\n",
       "      <td>2.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ppo</td>\n",
       "      <td>MountainCar-v0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-184055625.138</td>\n",
       "      <td>1055579.186</td>\n",
       "      <td>-92.338</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ppo</td>\n",
       "      <td>MountainCarContinuous-v0</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.015</td>\n",
       "      <td>111813348.743</td>\n",
       "      <td>1183510.514</td>\n",
       "      <td>1402.989</td>\n",
       "      <td>18.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ppo</td>\n",
       "      <td>Pendulum-v1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-3497349974.322</td>\n",
       "      <td>16938658.584</td>\n",
       "      <td>-1215.135</td>\n",
       "      <td>6.086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        method                       env  success rate  success rate sts  \\\n",
       "1       CAT-RL                Acrobot-v1         0.380             0.045   \n",
       "4       CAT-RL               CartPole-v1         0.000             0.000   \n",
       "16      CAT-RL            LunarLander-v2         0.000             0.000   \n",
       "7       CAT-RL            MountainCar-v0         0.965             0.020   \n",
       "10      CAT-RL  MountainCarContinuous-v0         0.706             0.423   \n",
       "13      CAT-RL               Pendulum-v1         0.019             0.015   \n",
       "2   TileCoding                Acrobot-v1         0.860             0.021   \n",
       "5   TileCoding               CartPole-v1         0.000             0.000   \n",
       "17  TileCoding            LunarLander-v2         0.017             0.001   \n",
       "8   TileCoding            MountainCar-v0         0.138             0.008   \n",
       "11  TileCoding  MountainCarContinuous-v0         0.706             0.036   \n",
       "14  TileCoding               Pendulum-v1         0.022             0.002   \n",
       "0         binQ                Acrobot-v1         0.513             0.017   \n",
       "3         binQ               CartPole-v1         0.000             0.000   \n",
       "15        binQ            LunarLander-v2         0.016             0.002   \n",
       "6         binQ            MountainCar-v0         0.198             0.013   \n",
       "9         binQ  MountainCarContinuous-v0         0.407             0.023   \n",
       "12        binQ               Pendulum-v1         0.022             0.002   \n",
       "18         ppo                Acrobot-v1         0.014             0.002   \n",
       "19         ppo               CartPole-v1         0.000             0.000   \n",
       "23         ppo            LunarLander-v2         0.000             0.000   \n",
       "20         ppo            MountainCar-v0         0.000             0.000   \n",
       "21         ppo  MountainCarContinuous-v0         0.145             0.015   \n",
       "22         ppo               Pendulum-v1         0.000             0.000   \n",
       "\n",
       "    accumulated reward  accumulated reward std  avg reward per episode  \\\n",
       "1       -347618363.500            79685500.774                 -55.285   \n",
       "4        251650810.200            57390804.337                  13.599   \n",
       "16     -4025443733.564            71502043.625                -196.053   \n",
       "7      14464492011.118           580858094.467                1161.639   \n",
       "10       188131599.149            42681942.763                 369.512   \n",
       "13    -19360056614.880          1090619204.989                -924.669   \n",
       "2       1020687281.900            92993773.390                 628.536   \n",
       "5        185847254.600             1584575.768                  10.062   \n",
       "17     -1761775790.133            37050527.710                 -97.726   \n",
       "8       1355634141.843           154421772.818                 107.614   \n",
       "11       534508976.190            41252351.573                1045.615   \n",
       "14    -12713250241.144           193108847.194                -672.821   \n",
       "0       -133942787.800            51462217.431                 129.762   \n",
       "3        205773254.000             5570689.014                  10.484   \n",
       "15     -1833856965.663            28385863.582                 -94.906   \n",
       "6        777513395.587            97302647.137                 173.669   \n",
       "9        661400922.269            23920781.425                1192.967   \n",
       "12    -15616340075.446           131421759.473                -668.949   \n",
       "18      -154483956.000              314872.537                -483.553   \n",
       "19        61333226.200              652239.629                  21.256   \n",
       "23      -236985767.351            10486693.915                 -82.696   \n",
       "20      -184055625.138             1055579.186                 -92.338   \n",
       "21       111813348.743             1183510.514                1402.989   \n",
       "22     -3497349974.322            16938658.584               -1215.135   \n",
       "\n",
       "    avg reward per episode std  \n",
       "1                       53.239  \n",
       "4                        3.942  \n",
       "16                       6.175  \n",
       "7                       48.126  \n",
       "10                      89.419  \n",
       "13                     139.056  \n",
       "2                       25.840  \n",
       "5                        0.064  \n",
       "17                       2.077  \n",
       "8                        8.868  \n",
       "11                     113.327  \n",
       "14                      10.915  \n",
       "0                       22.180  \n",
       "3                        0.238  \n",
       "15                       0.938  \n",
       "6                       16.418  \n",
       "9                       49.881  \n",
       "12                      10.810  \n",
       "18                       2.048  \n",
       "19                       0.219  \n",
       "23                       2.677  \n",
       "20                       0.710  \n",
       "21                      18.626  \n",
       "22                       6.086  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(l).sort_values(by=[\"method\", \"env\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_dict(methods, envs, seeds, folder=\"results-after-train\")\n",
    "\n",
    "l = []\n",
    "for env in envs:\n",
    "    for method in methods:\n",
    "        success_rate = []\n",
    "        accumulated_reward = []\n",
    "        for seed in seeds:\n",
    "            success_rate.append(mean(data[method][env][seed][\"success\"]))\n",
    "            accumulated_reward.append(sum(data[method][env][seed][\"accumulated reward\"]))\n",
    "            \n",
    "        avg_success_rate = mean(success_rate)\n",
    "        std_success_rate = std(success_rate)\n",
    "        avg_accumulated_reward = mean(accumulated_reward)\n",
    "        std_accumulated_reward = std(accumulated_reward)\n",
    "\n",
    "        l.append({\"method\": method, \"env\": env, \"success rate\": avg_success_rate, \"success rate sts\": std_success_rate, \"accumulated reward\": avg_accumulated_reward, \"accumulated reward std\": std_accumulated_reward})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results-after-train/ppo/Acrobot-v1/ppo_224.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43malgos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults-after-train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m envs:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m algo \u001b[38;5;129;01min\u001b[39;00m algos:\n",
      "File \u001b[0;32m~/github/Bachelor-Project/plot_utils.py:50\u001b[0m, in \u001b[0;36mdata_dict\u001b[0;34m(methods, envs, seeds, folder)\u001b[0m\n\u001b[1;32m     48\u001b[0m         data[method][env] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds:\n\u001b[0;32m---> 50\u001b[0m             data[method][env][seed] \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/github/Bachelor-Project/plot_utils.py:67\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(method, env, seed, folder)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(method, env, seed, folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     66\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 67\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# add column for accumulated reward\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccumulated reward\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcumsum()\n",
      "File \u001b[0;32m~/miniconda3/envs/rlexp/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rlexp/lib/python3.10/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/rlexp/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rlexp/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/rlexp/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results-after-train/ppo/Acrobot-v1/ppo_224.csv'"
     ]
    }
   ],
   "source": [
    "data = data_dict(algos, envs, seeds_icml, folder=\"results-after-train\")\n",
    "\n",
    "for env in envs:\n",
    "    for algo in algos:\n",
    "        success_rate = []\n",
    "        accumulated_reward = []\n",
    "        for seed in seeds_icml:\n",
    "            success_rate.append(mean(data[algo][env][seed][\"success\"]))\n",
    "            accumulated_reward.append(sum(data[algo][env][seed][\"accumulated reward\"]))\n",
    "            \n",
    "        avg_success_rate = mean(success_rate)\n",
    "        std_success_rate = std(success_rate)\n",
    "        avg_accumulated_reward = mean(accumulated_reward)\n",
    "        std_accumulated_reward = std(accumulated_reward)\n",
    "\n",
    "        l.append({\"method\": algo, \"env\": env, \"success rate\": avg_success_rate, \"success rate sts\": std_success_rate, \"accumulated reward\": avg_accumulated_reward, \"accumulated reward std\": std_accumulated_reward})\n",
    "\n",
    "\n",
    "df = pd.DataFrame(l).sort_values(by=[\"method\", \"env\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"results\"\n",
    "info_l = []\n",
    "for env in envs:\n",
    "    for method in methods:\n",
    "        time_l = []\n",
    "        for seed in seeds:\n",
    "            path = f\"{folder}/{method}/{env}/{method}_{seed}_info.csv\"\n",
    "            temp = pd.read_csv(path)\n",
    "            time_l.append(temp[\"time\"].values[-1])\n",
    "        mean_time = mean(time_l)\n",
    "        std_time = std(time_l)\n",
    "        info_l.append({\"method\": method, \"env\": env, \"time\": mean_time, \"std time\": std_time})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"results\"\n",
    "for env in envs:\n",
    "    max_episodes = max_episodes_dict[env]\n",
    "    policy_episodes, experiment_episodes = split_max_episodes(max_episodes) \n",
    "    for algo in algos:\n",
    "        time_l = []\n",
    "        for seed in seeds_icml:\n",
    "            \n",
    "            if env == \"MountainCarContinuous-v0\":\n",
    "                model = f\"icml_{policy_episodes}_{MOUNTAINCARCONTINUOUS_K}_{algo}_{experiment_episodes}\"\n",
    "            elif env == \"Pendulum-v1\":\n",
    "                model = f\"icml_{policy_episodes}_{PENDULUM_K}_{algo}_{experiment_episodes}\"\n",
    "            else:\n",
    "                model = f\"icml_{policy_episodes}_{algo}_{experiment_episodes}\" \n",
    "                \n",
    "            path = f\"{folder}/icml/{env}/{model}_{seed}_info.csv\"\n",
    "            temp = pd.read_csv(path)\n",
    "            time_l.append(temp[\"total_train_time\"].values[-1])\n",
    "        mean_time = mean(time_l)\n",
    "        std_time = std(time_l)\n",
    "        info_l.append({\"method\": algo, \"env\": env, \"time\": mean_time, \"std time\": std_time})\n",
    "\n",
    "info_df = pd.DataFrame(info_l).sort_values(by=[\"method\", \"env\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>env</th>\n",
       "      <th>time</th>\n",
       "      <th>std time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CAT-RL</td>\n",
       "      <td>MountainCarContinuous-v0</td>\n",
       "      <td>21.410</td>\n",
       "      <td>6.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TileCoding</td>\n",
       "      <td>MountainCarContinuous-v0</td>\n",
       "      <td>1314.878</td>\n",
       "      <td>83.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>binQ</td>\n",
       "      <td>MountainCarContinuous-v0</td>\n",
       "      <td>46.534</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ppo</td>\n",
       "      <td>MountainCarContinuous-v0</td>\n",
       "      <td>1148.086</td>\n",
       "      <td>35.347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        method                       env     time  std time\n",
       "10      CAT-RL  MountainCarContinuous-v0   21.410     6.642\n",
       "11  TileCoding  MountainCarContinuous-v0 1314.878    83.438\n",
       "9         binQ  MountainCarContinuous-v0   46.534     0.756\n",
       "21         ppo  MountainCarContinuous-v0 1148.086    35.347"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df[info_df[\"env\"]==\"MountainCarContinuous-v0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
